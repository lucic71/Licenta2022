\section{Porting Costs Evaluation}

% What I want to say in this section:
%   - I want to take the model of Tanaka and map my timeline on it (maybe merge
%   the model with [1])
%   - I want to talk about the porting tasks
%     - which was most time consuming
%     - which of them were repetitive and added little value
%     - etc
%   - I want to talk about the human and development factors as described in [1]
%   - talk about environment disparity and program factors; and how did this
%   affect the costs
%   - Finally I need to understand the equations for porting costs evaluation
%   and estimation in order to compare the resluts (and maybe talk about the
%   porting productivity index)
%
% The Tanaka+Hakuta model mapped on our timeline will be presented in a table.
% The indices from Hakuta([1]) will be presented in different subsection (idk).
%
% [1] "A study of Software Portability Evaluation"

In this section we present the costs associated with the porting process
described in the previous section. First we divide our work in tasks that can
be individually evaluated and later we discuss the factors that affected our
cost evaluation.

\subsection{Man-days costs}

In order to have an accurate cost evaluation of the porting process, we divided
our process into multiple subprocesses that can easily be evaluated using the
tracking created during the porting. We use man-days to evaluate the
cost for each subprocess because the tracking was done each week rather than
each day.

The anatomy of the porting process, as described in Tanaka et al. (citation
needed here) and Hakuta et al. (citation needed, there are only two authors,
should I name both instead saying "et al."?) with modification as per our
project needs has the following structure:
\begin{itemize}
    \item Advance preparations
        \begin{itemize}
            \item Surveying development environment
            \item Surveying target OS
            \item Surveying program for porting
            \item Surveying documentation
            \item Adjusting development environment
            \item Adjusting target environment
            \item Initial source code modifications
        \end{itemize}
    \item Building for target environment
        \begin{itemize}
            \item File-making
            \item Installation on remote environment
            \item Reviewing inconsistencies between source and remote environments
            \item Solving problems with external dependencies
            \item Create testing infrastructure
        \end{itemize}
    \item Testing
        \begin{itemize}
            \item Testing in simulated environment
            \item Testing in target environment
        \end{itemize}
    \item General duties
        \begin{itemize}
            \item Documentation
            \item Progress tracking
            \item Discussions
        \end{itemize}
\end{itemize}

Here we need a paragraph that clarifies some of the porting subprocesses.

This structure assumes that porting is a linear process, which is not the case.
Many tasks are repetitive between different stages of the project. For example
file-making occurs before and after testing in target environment takes place,
making it hard to accurately track each subtask. For this reason table
~\ref{tab:manHoursEvaluation} does not track the exact hours or days spent
on a specific subtask. It rather presents in how many days a specific subtask
was finished, even if that subtask took one or two hours of that day. Finally,
the last column of the table presents the number of days to finish a subtask
relative to the total number of days.

\begin{table*}
\centering
\begin{tabular}{ |c|c|c|c|c| }
\hline
Porting task & Subtasks & Days & Relative days \\
\hline
\multirow{7}{5em}{Advance preparations} & Surveying development environment & 5 & 8.33\\
& Surveying target OS & 5 & 8.33 \\
& Surveying program for porting & 5 & 8.33 \\
& Surveying documentation & 10 & 16.66 \\
& Adjusting development environment & 10 & 16.66 \\
& Adjusting target environment & 5 & 8.33 \\
& Initial source code modifications & 0 & 0 \\
\hline
\multirow{5}{5em}{Building for target environment} & File-making & 35  & 58.33\\
& Installation on remote environment & 40 & 66.66 \\
& Reviewing inconsistencies between source and remote environments & 50 & 79.63 \\
& Solving problems with external dependencies & 5 & 8.33 \\
& Create testing infrastructure & 15 & 25.00 \\
\hline
\multirow{2}{5em}{Testing} & Testing in simulated environment & 20  & 33.33\\
& Testing in target environment & 25 & 41.66 \\
\hline
\multirow{3}{5em}{General duties} & Documentation & 15  & 25.00 \\
& Progress tracking & 12 & 20.00 \\
& Discussions & 60 & 100.00 \\
\hline
\end{tabular}
\caption{Man-days evaluation for porting tasks}
\label{tab:manHoursEvaluation}
\end{table*}

As seen from the table the most time consuming subtask are the following:
discussions, incosistencies reviewing, installation on remote environment and
file-making. The amount of time spent on these tasks is different. While
discussions and inconsistencies reviewing were planned during the day, taking
a predefined amount of time, installation on remote environment and file-making
were repetitive and sporadic tasks. However this does not decrease the
importance of the later tasks, they were time consuming because they helped us
to achieve other tasks, mainly testing tasks.

Another thing that stands out is that we spent zero days on initial source code
modifications. This happened because the code base was too unfamiliar in order
to make source code modifications from the start. The first source code
modifications were present in the reviewing inconsistencies stage because the
toolchain helped us to discover the code zones to be changed.

\subsection{Factors of porting costs}

While porting costs, in our case man-days, are determined dirctly by program size and
content, other factors and impediments as human experience and environment
disparities must be taken into consideration.

To determine the impact some of these factors had on our porting process, we
use the indices described in Hakuta and Ohminami (citation needed) that give
a quantitative influence of porting factors and impediments.

The first index that we compute is the portability impediment index, this will
show us how portable was the porgram we ported and how many difficulties did
we meet in our porting process. The index is computed using the following
formula: $\alpha_p = \eta * \sum_{n=1}^{12} \omega_i S_i$, where $\eta$ is a
portability design index, $\omega_i$ is the weight assigned to each factor and
$S_i$ is 1 when the impediment $i$ exists, otherwise is 0. In our case $eta$
has a value of 2, meaning that "the non-portable parts of the program are not
localized, but the correspondence of program codes to their functions is
clarified". For simplicity we will assume that $\omega_i$ is 0 if the impediment
was insignificant, 0.5 if the impediment had a normal difficulty and 1 if the
impediment was hard to solve. In our porting we discovered the following
portability impediments:
\begin{itemize}
    \item Difference in compiler specification (S8)
    \item Scope of library support (S9)
    \item Implementation-dependent libraries (S10)
    \item Difference in operating system interface (S12)
\end{itemize}

It can be noted that we added an additional impediment inexistent in Hakuta and
Ohminami's list, namely S12, which can be placed in the "OS disparity" category.

Given these impediments the portability impediment index has the following
value: $\alpha_p = 2 * (0.5 * S8 + 1 * S9 + 1 * S10 + 0.5 * S12) = 6$. The
maximum value for $\alpha_p$ is 36. This number is achieved because there were
no differences between processor architecture (S1~S5), little difference between
source and target OSes (S6, S7, S12 and a major difference in language processor
(S8~S11). The application was written in C++ and the port was between two Linux
versions, which highly decreased the impediments we could have faced.
